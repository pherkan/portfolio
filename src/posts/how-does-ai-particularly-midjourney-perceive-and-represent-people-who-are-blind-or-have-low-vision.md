---
title: How does AI, particularly Midjourney, perceive and represent people who
  are blind or have low vision?
date: 2025-03-18T10:34:03.530Z
summary: Midjourney can be a great tool. But does it also understand when trying
  to create photos of a person that is blind or has low vision?
tags:
  - post
---
![A collage of AI-generated photos of people that are blind or have low vision.](/src/assets/img/1-5f7mlisgyd9uptprghnodq.webp "A collage of AI-generated photos of people that are blind or have low vision.")



Let’s delve into this topic and explore how Midjourney, a generative AI that can convert natural language prompts into images, can assist in creating photos of this specific group.

Before we dive in, allow me to provide a brief context. Currently, I work as a product manager and designer at Envision, where we develop AI-powered smart glasses [(Envision Glasses)](https://letsenvision.com/glasses) for people who are blind or have low vision. Our mission is to transform the visual world into spoken information.

As a startup, we face various challenges, one of which is obtaining a diverse range of photos showcasing our product in use by our target audience. Due to time constraints, limited resources, and lack of specialized equipment like high-quality cameras and proper lighting screens, we often find ourselves resorting to using the same photos from a campaign we ran over a year ago.

That’s where my exploration of Midjourney comes into play. I wanted to investigate if this AI tool could help us generate more varied content. However, I won’t keep you in suspense until the end of this article. The current state of AI, particularly Midjourney, doesn’t allow us to create consistent and realistic depictions of our product in use (yet!).

But let’s take a step back for a moment. Suppose I want to share something relevant for Global Accessibility Awareness Day and include an image of a person that is either blind or has low vision to provide additional context in a social media post. Can we, at least, achieve that?

In this article, I’ll showcase how AI interprets people who are blind or have low vision. The objective here is to create images that accurately represent individuals that are blind or have low vision.

I want to emphasize that many people who are blind or have low vision don’t necessarily rely on white canes, guide dogs, or would be wearing any sunglasses at all. However, for certain social media posts, we do need to depict a person using a white cane or accompanied by a guide dog, as this helps sighted individuals unfamiliar with the industry understand that the person is blind or has low vision and can benefit from our product, whether that is our (free!) [Envision App](https://letsenvision.com/app) or the [Envision Glasses](https://letsenvision.com/glasses).

I’ll share the prompts I used and the corresponding image outputs from Midjourney. Keep in mind that when using Midjourney, it always provides four different images as output.



## Prompt 1: A person that is blind

![4 photos of men, 3 of them are wearing a cloth on their face, the top left one is an asian-looking man wearing aviator sunglasses. all of the photos are in a dark shade and have something mysterious to it.](/src/assets/img/1-p24ygydrk0n7eczaga20nw-2.webp "4 photos showing 'supposedly' blind people")